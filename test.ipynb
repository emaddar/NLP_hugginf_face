{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 15:27:20,607 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, B-LOC, E-LOC, S-LOC, B-MISC, E-MISC, B-PER, E-PER, S-PER, I-MISC, I-PER, I-LOC, S-MISC, B-ORG, E-ORG, I-ORG, S-ORG, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-french\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence(\"The grass is green .'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[6]: \"George Washington went to Washington .\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span[0:2]: \"George Washington\" → PER (0.7136)\n",
      "Span[4:5]: \"Washington\" → LOC (0.6779)\n"
     ]
    }
   ],
   "source": [
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can get confidence score of each of the predicted entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'value': 'PER', 'confidence': 0.7136043012142181}, {'value': 'LOC', 'confidence': 0.677897036075592}]\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_dict(tag_type='ner')['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def download_file(url, output_file):\n",
    "  Path(output_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "  urllib.request.urlretrieve (url, output_file)\n",
    "\n",
    "conllpp_train = pd.read_csv('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_train.txt', sep =\" \", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conllpp_dev = pd.read_csv('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_dev.txt',  sep =\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conllpp_test = pd.read_csv('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_test.txt', sep = \" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "conllpp_train.to_csv('conllpp_train.csv', sep= \" \")\n",
    "conllpp_dev.to_csv('conllpp_dev.csv', sep= \" \")\n",
    "conllpp_test.to_csv('conllpp_test.csv', sep= \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:31:44,609 Reading data from data\n",
      "2023-03-21 16:31:44,611 Train: data/conllpp_train.txt\n",
      "2023-03-21 16:31:44,612 Dev: data/conllpp_dev.txt\n",
      "2023-03-21 16:31:44,613 Test: data/conllpp_test.txt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "columns = {0: 'text', 3: 'ner'}\n",
    "corpus: Corpus = ColumnCorpus('data/', columns,\n",
    "                              train_file='conllpp_train.txt',\n",
    "                              test_file='conllpp_test.txt',\n",
    "                              dev_file='conllpp_dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Development</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14987</td>\n",
       "      <td>3684</td>\n",
       "      <td>3466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train  Test  Development\n",
       "0  14987  3684         3466"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [[len(corpus.train), len(corpus.test), len(corpus.dev)]]\n",
    "# Prints out the dataset sizes of train test and development in a table.\n",
    "pd.DataFrame(data, columns=[\"Train\", \"Test\", \"Development\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16494/2905434251.py:8: DeprecationWarning: Call to deprecated method make_tag_dictionary. (Use 'make_label_dictionary' instead.) -- Deprecated since version 0.8.\n",
      "  tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:34:18,569 SequenceTagger predicts: Dictionary with 3 tags: O, <START>, <STOP>\n",
      "2023-03-21 16:34:18,800 ----------------------------------------------------------------------------------------------------\n",
      "2023-03-21 16:34:18,802 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2023-03-21 16:34:18,804 ----------------------------------------------------------------------------------------------------\n",
      "2023-03-21 16:34:18,805 Corpus: \"Corpus: 14987 train + 3466 dev + 3684 test sentences\"\n",
      "2023-03-21 16:34:18,806 ----------------------------------------------------------------------------------------------------\n",
      "2023-03-21 16:34:18,807 Parameters:\n",
      "2023-03-21 16:34:18,808  - learning_rate: \"0.100000\"\n",
      "2023-03-21 16:34:18,809  - mini_batch_size: \"32\"\n",
      "2023-03-21 16:34:18,809  - patience: \"3\"\n",
      "2023-03-21 16:34:18,810  - anneal_factor: \"0.5\"\n",
      "2023-03-21 16:34:18,811  - max_epochs: \"50\"\n",
      "2023-03-21 16:34:18,812  - shuffle: \"True\"\n",
      "2023-03-21 16:34:18,813  - train_with_dev: \"False\"\n",
      "2023-03-21 16:34:18,813  - batch_growth_annealing: \"False\"\n",
      "2023-03-21 16:34:18,815 ----------------------------------------------------------------------------------------------------\n",
      "2023-03-21 16:34:18,816 Model training base path: \"model/conllpp\"\n",
      "2023-03-21 16:34:18,817 ----------------------------------------------------------------------------------------------------\n",
      "2023-03-21 16:34:18,818 Device: cpu\n",
      "2023-03-21 16:34:18,819 ----------------------------------------------------------------------------------------------------\n",
      "2023-03-21 16:34:18,820 Embeddings storage mode: gpu\n",
      "2023-03-21 16:34:18,820 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "from typing import List\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.models import SequenceTagger\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "\n",
    "tag_type = 'ner'\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "\n",
    "# For faster training and smaller models, we can comment out the flair embeddings.\n",
    "# This will significantly affect the performance though.\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    WordEmbeddings('glove'),\n",
    "    FlairEmbeddings('news-forward'),\n",
    "    FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train('model/conllpp',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=50,\n",
    "              embeddings_storage_mode='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
